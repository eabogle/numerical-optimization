{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a15b26-ef7b-4878-a49f-29a5fdb50d09",
   "metadata": {},
   "source": [
    "### MTH 610 Model Constrained Optimization 1 (Homework 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8528cbde-d290-4a29-976b-e166ec60e0c6",
   "metadata": {},
   "source": [
    "##### Emily Bogle\n",
    "##### 10/17/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a690c-cd7d-4b55-8167-81eb547c713e",
   "metadata": {},
   "source": [
    "#### Problem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edc8aa-dcf2-40c2-bfa9-be9e293d8750",
   "metadata": {},
   "source": [
    "Consider the boundary value problem (BVP) for a function $x:[0,1] \\to \\mathbb{R}$,\n",
    "$$\n",
    "\\begin{cases}\n",
    "-x''(t)+x^3(t)=u\\\\\n",
    "(x(0)=0, \\quad x(1)=0\n",
    "\\end{cases}\n",
    "$$\n",
    "where $u\\in\\mathbb{R}$ is a constant scalar parameter. In this assignment we want to find an optimal parameter value $u^*$ such that the solution $x(t)$ to the BVP minimizes the cost functional \n",
    "$$\n",
    "J(x,u)=\\frac{\\omega}{2}|u|^2+\\frac{1}{2}\\int_0^1|x(t)-\\overline{x}(t)|^2dt\n",
    "$$\n",
    "where $\\overline{x}(t)$ is a given function (desired outcome/goal, measurement) and $\\omega\\geq 0$ is a specified fixed weight parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6049ce4-6b1e-467f-aac7-1ce807af766e",
   "metadata": {},
   "source": [
    "#### Part 1 (Optimality Conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717d7c5e-72e8-4fbe-9224-c95fa8b84286",
   "metadata": {},
   "source": [
    "We know that \n",
    "$$\n",
    "\\delta J = \\omega u \\delta u +\\int_0^1 (x(t)-\\overline{x}(t))\\delta x dt.\n",
    "$$\n",
    "Now, the variation in the model is given by the following:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "-\\delta x'' + 3x^2\\delta x = \\delta u \\\\\n",
    "\\delta x(0)=0, \\quad \\delta x(1)=0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We will take the inner product with the lambda function to get,\n",
    "$$\n",
    "\\int_0^1-\\delta x''\\lambda + 3x^2\\delta x \\lambda dt = \\int_0^1\\delta u \\lambda dt \\\\\n",
    "\\implies -\\delta x'\\lambda |_0^1 +\\int_0^1 \\delta x'\\lambda' + 3x^2\\delta x \\lambda dt = \\int_0^1 \\delta u dt\\\\\n",
    "\\implies (-\\delta x'\\lambda + \\delta x \\lambda')|_0^1 + \\int_0^1 -\\lambda''\\delta x + 3x^2\\lambda \\delta x dt = \\int_0^1 \\delta u \\lambda dt \\\\\n",
    "\\implies -\\delta x'(1) \\lambda (1) + \\delta x(1) \\lambda' (1) - (-\\delta x'(0) \\lambda (0) + \\delta x(0) \\lambda' (0)) + \\int_0^1 -\\lambda'' \\delta (x) + 3x^2 \\lambda \\delta (x) dt = \\int_0^1 \\delta u \\lambda dt\n",
    "$$\n",
    "\n",
    "Therfore, we define $\\lambda (t)$ solution to the BVP (adjoint model) as the following:\n",
    "$$\n",
    "\\begin{cases}\n",
    "-\\lambda''(t) +3(x(t))^2 \\lambda(t) = x(t) - \\overline{x}(t) \\\\\n",
    "\\lambda (0) =0, \\quad \\lambda(1)=0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "With this definition of $\\lambda (t)$ we obtain $\\delta J$ in terms of $\\delta u$,\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\delta J &= \\omega u \\delta u +\\int_0^1 \\delta u \\lambda(t) dt\\\\\n",
    "&= [\\omega u + \\int_0^1 \\lambda(t) dt]\\delta u\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Now, the optimality condition ($\\nabla_u J=0$) is given by,\n",
    "$$\n",
    "\\omega u + \\int_0^1 \\lambda(t) dt =0\n",
    "$$\n",
    "\n",
    "Therefore our first order optimality conditions (Euler Lagrange Equations) for the minmization of the cost functional subject the the BVP constraint are given by,\n",
    "$$\n",
    "\\begin{cases}\n",
    "-x''(t)+x^3(t)=u\\\\\n",
    "-\\lambda''(t) + 3(x(t))^2\\lambda(t) = x(t)-\\overline{x}(x)\\\\\n",
    "x(0)=0, \\quad x(1)=0\\\\\n",
    "\\lambda(0)=0, \\quad \\lambda(1)=0\n",
    "\\end{cases}\n",
    "$$\n",
    "with the optimality condition:\n",
    "$$\n",
    "\\omega u +\\int_0^1 \\lambda(t)dt =0\n",
    "$$\n",
    "where we know $\\nabla_u J = \\omega u +\\int_0^1 \\lambda(t)dt$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9664fed5-60e4-425e-be1a-4ea1fc790794",
   "metadata": {},
   "source": [
    "#### Part 2 (Use Method of Choice to Estimate $u^*$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c792e9fd-a054-43e7-a2d1-e1574d553934",
   "metadata": {},
   "source": [
    "With the given optimality system we can discretize and then optimize. After discretizing the two systems of PDEs both become a system of nonlinear equations to solve. Furthermore, in this way we can start wtih an initial $u$ value, and then from that we can find $x$ givne the model BVP constraint, and then once we have $x$ we can solve for $\\lambda$ using the adjoint model. Then we will cycle through this process in doing steepest descent iterations on $\\nabla_u J$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25c2402-38db-4e26-9fcd-5749c9cb66ce",
   "metadata": {},
   "source": [
    "A discrete version to the original BVP is obtained by considering a uniform partition of the interval $[0,1]$ with nodes $\\{t_i:i=0:n+1\\}$ at an increment $h=\\frac{1}{N+1}$,\n",
    "$$\n",
    "0=t_0<t_1<\\dots<t_N<t_{N+1}=1, \\quad t_i=i*h \\textrm{ for } i=0:N+1\n",
    "$$\n",
    "and an approximation for the second order derivative using a finite difference formula is \n",
    "$$\n",
    "x''(t_i)\\approx\\frac{x(t_{i+1})-2x(t_i)+x(t_{i-1})}{h^2}, \\quad i=1:N\n",
    "$$\n",
    "\n",
    "Therefore a discrete version of the BVP is given by,\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\frac{x_{i+1}-2x_i+x_{i-1}}{h^2} + x^3_{i} = u_i, \\quad i=1:N\\\\\n",
    "x_0=0, \\quad x_{N+1}=0\n",
    "\\end{cases}\n",
    "$$\n",
    "where $x_i\\approx x(t_i), \\quad i=1:N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a370e-1ff9-4272-b599-9f777989fef4",
   "metadata": {},
   "source": [
    "We can write this sytem of equations in matrix vector format,\n",
    "$$\n",
    "\\mathbf{A}\\mathbf{x}+\\mathbf{G}(\\mathbf{x})=u\\mathbf{1_N}\n",
    "$$\n",
    "where $u \\in \\mathbb{R}$ is a scalar, $\\mathbf{1_N}\\in \\mathbb{R}^N$ is the constant vector of 1's, $\\mathbf{A}\\in \\mathbb{R}^{N*N}$ is a scaled tridaigonal matix with 2 on the main diagonal and -1 on the neighboring minor diagonals and the scaling constant is given by $\\frac{1}{h^2}$, and $\\mathbf{G}:\\mathbb{R}^N\\to\\mathbb{R}^N$ is a vector valued funcition with $x_i^3$ in each component. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9afca-dde6-4d3f-a200-2a37ecaf6c5a",
   "metadata": {},
   "source": [
    "Similarly after discretizing $\\lambda$ in time, we can write the other system of equations ivolving $\\lambda$ in matrix vector format,\n",
    "$$\n",
    "\\mathbf{A}\\mathbf{\\lambda}+\\mathbf{F}(\\mathbf{x,\\lambda})= \\mathbf{x} - \\mathbf{\\overline{x}}\n",
    "$$\n",
    "where $\\mathbf{F}:\\mathbb{R}^N\\to\\mathbb{R}^N$ is a vector valued funcition with $3x_i^2*\\lambda_i$ in each component, and $\\mathbf{\\overline{x}}$ is a time discretized vector with components based on the given goal function provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d75297-1fc7-463d-979e-63d93ffe4738",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26ad9dc9-843e-42b7-8f03-4c67f425eb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import needed packages\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sympy\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3cb4ef25-b34d-45da-a405-40586254022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution for x: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Solution for lambda: [-0.00311918 -0.00623836 -0.0093544  -0.01246416 -0.01556451 -0.01865233\n",
      " -0.0217245  -0.02477793 -0.02780955 -0.0308163  -0.03379516 -0.03674311\n",
      " -0.03965718 -0.04253445 -0.045372   -0.04816697 -0.05091654 -0.05361794\n",
      " -0.05626843 -0.05886534 -0.06140604 -0.06388796 -0.0663086  -0.06866549\n",
      " -0.07095625 -0.07317855 -0.07533014 -0.07740884 -0.07941253 -0.08133916\n",
      " -0.08318678 -0.0849535  -0.08663751 -0.08823708 -0.08975058 -0.09117646\n",
      " -0.09251323 -0.09375951 -0.09491403 -0.09597556 -0.09694301 -0.09781535\n",
      " -0.09859166 -0.09927111 -0.09985298 -0.10033661 -0.10072147 -0.10100713\n",
      " -0.10119322 -0.10127952 -0.10126586 -0.1011522  -0.1009386  -0.10062519\n",
      " -0.10021222 -0.09970004 -0.0990891  -0.09837992 -0.09757315 -0.09666953\n",
      " -0.09566987 -0.09457511 -0.09338626 -0.09210444 -0.09073084 -0.08926675\n",
      " -0.08771357 -0.08607275 -0.08434586 -0.08253454 -0.08064051 -0.07866558\n",
      " -0.07661163 -0.07448063 -0.07227462 -0.06999571 -0.0676461  -0.06522802\n",
      " -0.06274382 -0.06019587 -0.05758664 -0.05491862 -0.0521944  -0.04941659\n",
      " -0.04658788 -0.043711   -0.04078871 -0.03782385 -0.03481927 -0.03177788\n",
      " -0.02870262 -0.02559645 -0.02246239 -0.01930345 -0.0161227  -0.01292322\n",
      " -0.00970809 -0.00648043 -0.00324335]\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "omega = 1\n",
    "N=99\n",
    "h=1/(N+1)\n",
    "\n",
    "# Define A (discrete Laplace) matrix\n",
    "main_diag = 2 * np.eye(N)\n",
    "minor_diags = -1 * (np.eye(N, k=-1) + np.eye(N, k=1))\n",
    "A = 1/(h*h) * (main_diag + minor_diags)\n",
    "\n",
    "# Create initial guess vector u for fsolve, and initlial vectors needed to define xbar vector\n",
    "u_guess = 0\n",
    "u_guess_vect = u_guess * np.ones(N)\n",
    "t_nodes = np.zeros(N)\n",
    "x_bar = np.zeros(N)\n",
    "\n",
    "# Create xbar vector based off xbar(t) = sin(pi*t)\n",
    "def xbar(t):\n",
    "    return np.sin(np.pi * t)\n",
    "\n",
    "for i in range(N):\n",
    "    t_nodes[i] = i*h\n",
    "    x_bar[i] = xbar(t_nodes[i])\n",
    "    \n",
    "# Create initial guess vector x for fsolve with 0 boundary conditions\n",
    "x_guess = np.zeros(N)\n",
    "x_guess[0] = 0\n",
    "x_guess[-1] = 0\n",
    "\n",
    "# Create initial guess vector x for fsolve with 0 boundary conditions\n",
    "lamb_guess = np.zeros(N)\n",
    "lamb_guess[0] = 0\n",
    "lamb_guess[-1] = 0\n",
    "\n",
    "# Define nonlinear system of equations for x BVP to find roots of using fsolve\n",
    "def xequation(x, A, u):\n",
    "    return A @ x + x**3 - u\n",
    "\n",
    "# Define nonlinear system of equations for lambda BVP to find roots of using fsolve\n",
    "def lambequation(lamb, A, x, xbar):\n",
    "    return A @ lamb + 3*(x**2) * lamb - x + xbar\n",
    "\n",
    "# Use fsolve to find approximate solution of x BVP\n",
    "resultx = fsolve(xequation, x_guess, args=(A, u_guess_vect), xtol=1e-8)\n",
    "print(\"Solution for x:\", resultx)\n",
    "\n",
    "# Use fsolve to find approximate solution of lambda BVP\n",
    "resultlamb = fsolve(lambequation, lamb_guess, args=(A, resultx, x_bar), xtol=1e-8)\n",
    "print(\"Solution for lambda:\", resultlamb)\n",
    "\n",
    "# Define steepest descent move for new u_guess value\n",
    "def steepest_descent_move(gradient, u_guess, step):\n",
    "    return u_guess - (step * gradient)\n",
    "\n",
    "# Define gradient with respect to u of the cost function J\n",
    "def gradju(omega, u_guess, resultlamb):\n",
    "    integral = np.trapz(resultlamb, dx=1/len(resultlamb))\n",
    "    return omega * u_guess + integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02a2169d-d002-433d-bebe-40eab4530e93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 1550 iterations.\n",
      "Optimal u value: 0.06454629140937759\n"
     ]
    }
   ],
   "source": [
    "maxiter = 10000\n",
    "tol = 1e-8\n",
    "step = 0.01\n",
    "iteration = 0\n",
    "\n",
    "while (iteration < maxiter):\n",
    "    gradient_mag = np.abs(gradju(omega, u_guess, resultlamb))\n",
    "    \n",
    "    if gradient_mag < tol:\n",
    "        print(f\"Converged after {iteration + 1} iterations.\")\n",
    "        print(f\"Optimal u value:\", u_guess)\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        u_guess = steepest_descent_move(gradient, u_guess, step)\n",
    "        u_guess_vect = u_guess * np.ones(N)\n",
    "        resultx = fsolve(xequation, x_guess, args=(A, u_guess_vect), xtol=1e-8)\n",
    "        resultlamb = fsolve(lambequation, lamb_guess, args=(A, resultx, x_bar), xtol=1e-8)\n",
    "        gradient = gradju(omega, u_guess, resultlamb)\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "if iteration == maxiter:\n",
    "    print(\"Maximum iterations reached without convergence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7029e-efd8-44a8-b4cc-a8acfd1236a3",
   "metadata": {},
   "source": [
    "#### Part 3 (Validate Estimate $u^*$)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:optimization]",
   "language": "python",
   "name": "conda-env-optimization-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
